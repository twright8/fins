---
# Document Processing
document_processing:
  chunk_size: 512
  chunk_overlap: 50
  ocr_parallel_jobs: 4
  coref_batch_size: 256  # Batch size for coreference resolution

# Models
models:
  # Retrieval and indexing embedding model
  embedding_model: "intfloat/multilingual-e5-base"
  # Semantic chunking embedding model (can be the same or different)
  semantic_chunking_model: "intfloat/multilingual-e5-small"
  # Other models
  reranking_model: "BAAI/bge-reranker-v2-m3"
  ner_model: "flair/ner-english-ontonotes-fast"
  coref_model: "FCoref"
  llm_model: "Qwen/Qwen2.5-0.5B-Instruct"

# Retrieval
retrieval:
  top_k_vector: 20
  top_k_bm25: 10
  top_k_hybrid: 15
  top_k_rerank: 5
  vector_weight: 0.7
  bm25_weight: 0.3
  indexing_batch_size: 0  # 0 means auto (len/4)

# LLM Generation
generation:
  # Common parameters
  temperature: 0.3
  max_tokens: 1024
  top_p: 0.9
  top_k: 50
  presence_penalty: 0.0
  
  # Provider selection - can be "aphrodite" or "deepseek"
  provider: "aphrodite"
  
  # Aphrodite (local) configuration
  aphrodite:
    model: "Qwen/Qwen2.5-0.5B-Instruct"
    max_model_len: 8192
    gpu_memory_utilization: 0.85
    quantization: "fp8"
  
  # DeepSeek API configuration
  deepseek:
    api_key: ""  # Add your DeepSeek API key here to enable DeepSeek
    api_base: "https://api.deepseek.com/v1"
    model: "deepseek-chat"
    timeout: 60

# Qdrant Vector DB
qdrant:
  host: "localhost"
  port: 6333
  collection_name: "anti_corruption_docs"
  vector_size: 768

# Entity Extraction
entity_extraction:
  confidence_threshold: 0.3
  relationship_threshold: 0.3
  fuzzy_match_threshold: 90  # Fuzzy matching threshold (0-100) for entity deduplication
  ner_batch_size: 64  # Batch size for NER predictions (adjust based on VRAM)
  relation_batch_size: 32  # Batch size for relationship predictions

# UI
ui:
  page_title: "Anti-Corruption RAG System"
  page_icon: "üîç"
  theme_color: "#1E3A8A"
  accent_color: "#3B82F6"
  max_upload_size_mb: 200
